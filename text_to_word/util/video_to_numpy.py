import cv2
import mediapipe as mp
import numpy as np
import json
import os
import re
import math
from pathlib import Path

# ==== ì‚¬ìš©ì ì„¤ì • ====
with open("/home/202044005/KSEB/text_to_word/preprocessed_data/unique_glosses.json", 'r', encoding='utf-8') as f:
    TARGET_LABELS = json.load(f)



TARGET_LABELS = ["ê°€ë‹¤1","ì˜¤ë‹¤1","ì§‘1","ë¬¼ê±´2","ê²°ì •1","ì¤€ë¹„1","ì›ì¸1","ì´ì „1","ë•Œ2","ë¨¹ë‹¤1"]
PER_LABEL_LIMIT = 500
BUFFER_FRAMES = 5
MIN_VALID_FRAMES = 7          # ğŸ”¸ ë„ˆë¬´ ì§§ì€ êµ¬ê°„ì€ ë²„ë¦¼
APPLY_EMA = False             # ğŸ”¸ íŠ í”„ë ˆì„ ì™„í™”(ì§€ìˆ˜ì´ë™í‰ê· )
EMA_ALPHA = 0.5
APPLY_SPIKE_GUARD = True      # ğŸ”¸ 2~3í”„ë ˆì„ ì—°ì† í° ì í”„ë©´ ì„¸ê·¸ë¨¼íŠ¸ íê¸°
SPIKE_THRESH = 0.35           #   (0~1 í™”ë©´ì¢Œí‘œ ê¸°ì¤€ ëŒ€ëµê°’, í•„ìš”ì‹œ ì¡°ì •)
SPIKE_RUN = 2
NORMALIZE_TO_SHOULDERS = False # ğŸ”¸ ì–´ê¹¨ ì¤‘ì‹¬ ì •ê·œí™”(ê¸°ì¡´ í•™ìŠµê³¼ ë‹¤ë¥´ë©´ False)

# ==== ê²½ë¡œ ì„¤ì • ====
root_folder = r"/storage/202044005/data"
output_dir = r"/storage/202044005/numpy"
os.makedirs(output_dir, exist_ok=True)

POSE_INDEXES = list(range(17))  # 0..16 (ì–¼êµ´+ì–´ê¹¨/íŒ” ìœ„ì£¼, 17~ëŠ” ì œì™¸)
expected_len = 21*3 + 21*3 + 17*4  # = 194

mp_holistic = mp.solutions.holistic

def sanitize_filename(name):
    return re.sub(r'[:\/\\?*<>|"]', '_', name)

def extract_landmarks(landmarks, dims, idxs=None):
    result = []
    if landmarks:
        it = (enumerate(landmarks.landmark) if idxs is None
            else ((i, landmarks.landmark[i]) for i in idxs))
        for _, lm in it:
            coords = [lm.x, lm.y, lm.z]
            if dims == 4:
                coords.append(getattr(lm, 'visibility', 0.0))
            result.extend(coords)
    return result

def ema_smooth(seq, alpha=EMA_ALPHA):
    """seq: (T, D) numpy. ê°„ë‹¨ EMA. 0ë§Œì¸ í”„ë ˆì„ì€ ê·¸ëŒ€ë¡œ ë‘ ."""
    if len(seq) == 0:
        return seq
    out = seq.copy()
    for t in range(1, len(seq)):
        prev = out[t-1]
        curr = seq[t]
        # ëª¨ë‘ 0ì¸ í”„ë ˆì„ì€ ìŠ¤í‚µ(ê²€ì¶œ ì‹¤íŒ¨ í”„ë ˆì„)
        if not np.any(curr):
            out[t] = curr
        else:
            out[t] = alpha * curr + (1 - alpha) * prev
    return out

def has_spike(seq, thresh=SPIKE_THRESH, run=SPIKE_RUN):
    """ì—°ì† run í”„ë ˆì„ ì´ìƒ í° ì í”„ê°€ ìˆëŠ”ì§€ ê²€ì‚¬(ì†+í¬ì¦ˆ ì „ì²´ L2)."""
    if len(seq) < run + 1:
        return False
    # ì¢Œí‘œë§Œ(visibility ì œì™¸) ì‚¬ìš©: 21*3 + 21*3 + 17*3 = 63+63+51 = 177
    # ì•„ë˜ëŠ” visibility í¬í•¨ 194ì—ì„œ ë§ˆì§€ë§‰ 17ê°œë¥¼ ì œì™¸
    coord_dim = expected_len - 17  # 177
    diffs = np.linalg.norm(np.diff(seq[:, :coord_dim], axis=0), axis=1)
    # 0ë§Œì¸ í”„ë ˆì„ë“¤ ì‚¬ì´ diffëŠ” ì‘ê²Œ ë‚˜ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ë¹„ì œë¡œ í”„ë ˆì„ë“¤ ì¤‘ì‹¬ìœ¼ë¡œ íŒë‹¨í•˜ë©´ ë” ì •êµí•¨
    count = 0
    for d in diffs:
        if d > thresh:
            count += 1
            if count >= run:
                return True
        else:
            count = 0
    return False

def normalize_by_shoulders(frame_vec):
    """
    frame_vec: (194,) [lh(63) + rh(63) + pose(68)]
    í¬ì¦ˆì—ì„œ ì¢Œ/ìš° ì–´ê¹¨(landmark 11,12)ì˜ x,yë¥¼ ì‚¬ìš©í•´ ì¤‘ì‹¬/ìŠ¤ì¼€ì¼ ì •ê·œí™”.
    z/visibilityëŠ” ê·¸ëŒ€ë¡œ ë‘ .
    """
    if len(frame_vec) != expected_len:
        return frame_vec
    lh = frame_vec[0:63]
    rh = frame_vec[63:126]
    pose = frame_vec[126:]  # 17*4

    # poseì—ì„œ 11,12ë²ˆì§¸(ê¸€ë¡œë²Œ ì¸ë±ìŠ¤ ê¸°ì¤€)ê°€ í¬í•¨ë¼ ìˆìŒ(0..16 ì¤‘ 11,12 ì¡´ì¬)
    # pose ë¸”ë¡ ë‚´ì—ì„œ ê° í¬ì¸íŠ¸ëŠ” [x,y,z,vis] ìˆœìœ¼ë¡œ 4ê°œì”©
    def get_xy(pose_block, idx_in_pose):
        base = idx_in_pose * 4
        return pose_block[base], pose_block[base+1]

    try:
        lx, ly = get_xy(pose, 11)  # left shoulder
        rx, ry = get_xy(pose, 12)  # right shoulder
        cx, cy = (lx + rx) / 2.0, (ly + ry) / 2.0
        scale = max(np.hypot(rx - lx, ry - ly), 1e-6)

        def norm_xy_block(block, step):
            out = block.copy()
            # step=3 for hands, step=4 for pose (xyëŠ” ê° í¬ì¸íŠ¸ì˜ ì²˜ìŒ 2ê°œ)
            for i in range(0, len(block), step):
                out[i]   = (block[i]   - cx) / scale
                out[i+1] = (block[i+1] - cy) / scale
            return out

        lh2 = norm_xy_block(lh, 3)
        rh2 = norm_xy_block(rh, 3)
        pose2 = pose.copy()
        for i in range(0, len(pose), 4):
            pose2[i]   = (pose[i]   - cx) / scale
            pose2[i+1] = (pose[i+1] - cy) / scale
        return np.concatenate([lh2, rh2, pose2], axis=0)
    except Exception:
        return frame_vec

# ==== ì „ì²´ í´ë” ë‚´ json/mp4 íƒìƒ‰ ====
all_json_paths = []
for dirpath, _, filenames in os.walk(root_folder):
    for fname in filenames:
        if fname.endswith(".json"):
            base = os.path.splitext(fname)[0]
            json_path = os.path.join(dirpath, f"{base}.json")
            video_path = os.path.join(dirpath, f"{base}.mp4")
            if os.path.exists(video_path):
                all_json_paths.append((base, json_path, video_path))

print(f"ğŸ” ì´ {len(all_json_paths)}ê°œ JSON/MP4 ì„¸íŠ¸ ë°œê²¬ë¨")

# ë¼ë²¨ë³„ ë³€í™˜ ê°œìˆ˜ ì¹´ìš´í„°
converted_counts = {label: 0 for label in TARGET_LABELS}

# ==== ì²˜ë¦¬ ====
for base_id, json_path, video_path in all_json_paths:

    # ëª¨ë“  ë¼ë²¨ ìƒí•œ ì±„ìš°ë©´ ì¢…ë£Œ
    if all(converted_counts[lbl] >= PER_LABEL_LIMIT for lbl in TARGET_LABELS):
        print("\nâœ… ëª¨ë“  ë¼ë²¨ ë³€í™˜ ì™„ë£Œ (ì €ì¥ ê¸°ì¤€)")
        break

    with open(json_path, "r", encoding="utf-8") as f:
        data = json.load(f)
    fps = data.get("potogrf", {}).get("fps", 30) or 30
    signs = data.get("sign_script", {}).get("sign_gestures_strong", [])
    if not signs:
        continue

    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print(f"âŒ ë¹„ë””ì˜¤ ì—´ê¸° ì‹¤íŒ¨: {video_path}")
        continue

    with mp_holistic.Holistic(min_detection_confidence=0.7,
                                min_tracking_confidence=0.7,
                                model_complexity=1) as holistic:  # ğŸ”¸ ì„±ëŠ¥/ì†ë„ ê· í˜•
        for seg_idx, gloss in enumerate(signs, start=1):
            gloss_id = str(gloss.get('gloss_id', '')).strip()
            if gloss_id not in TARGET_LABELS:
                continue
            if converted_counts[gloss_id] >= PER_LABEL_LIMIT:
                continue

            # íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€: start~end í”„ë ˆì„ í¬í•¨
            start_sec = float(gloss['start'])
            end_sec = float(gloss['end'])
            start_frame = int(math.floor(start_sec * fps))
            end_frame   = int(math.ceil(end_sec * fps))
            buffer_start = max(start_frame - BUFFER_FRAMES, 0)

            gloss_id_clean = sanitize_filename(gloss_id)
            label_dir = os.path.join(output_dir, gloss_id_clean)
            os.makedirs(label_dir, exist_ok=True)

            out_name = f"{base_id}_{gloss_id_clean}_{start_frame:06d}-{end_frame:06d}.npy"
            out_path = os.path.join(label_dir, out_name)
            if os.path.exists(out_path):
                print(f"  â© ì´ë¯¸ ì¡´ì¬, ê±´ë„ˆëœ€: {out_path}")
                continue

            try:
                cap.set(cv2.CAP_PROP_POS_FRAMES, buffer_start)
                frames = []
                for frame_idx in range(buffer_start, end_frame + 1):
                    ret, frame = cap.read()
                    if not ret:
                        break
                    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    results = holistic.process(image_rgb)
                    if frame_idx < start_frame:
                        continue

                    lh = extract_landmarks(results.left_hand_landmarks, 3)
                    rh = extract_landmarks(results.right_hand_landmarks, 3)
                    pose = extract_landmarks(results.pose_landmarks, 4, idxs=POSE_INDEXES)

                    keypoints = lh + rh + pose
                    if len(keypoints) < expected_len:
                        keypoints += [0.0] * (expected_len - len(keypoints))
                    elif len(keypoints) > expected_len:
                        keypoints = keypoints[:expected_len]

                    frames.append(keypoints)

                seq = np.array(frames, dtype=np.float32)  # ğŸ”¸ float32ë¡œ ì €ì¥ ìš©ëŸ‰ ì ˆê°
                # ìµœì†Œ ê¸¸ì´ í•„í„°
                if len(seq) < MIN_VALID_FRAMES:
                    print(f"  âš ï¸ ë„ˆë¬´ ì§§ìŒ({len(seq)}í”„ë ˆì„), ê±´ë„ˆëœ€: {out_name}")
                    continue

                # ìŠ¤íŒŒì´í¬ ê°ì§€ â†’ íê¸°(ì˜µì…˜)
                if APPLY_SPIKE_GUARD and has_spike(seq, SPIKE_THRESH, SPIKE_RUN):
                    print(f"  âš ï¸ ì¢Œí‘œ ìŠ¤íŒŒì´í¬ ê°ì§€, ê±´ë„ˆëœ€: {out_name}")
                    continue

                # EMA ìŠ¤ë¬´ë”©(ì˜µì…˜)
                if APPLY_EMA:
                    seq = ema_smooth(seq)

                # ì–´ê¹¨ ì •ê·œí™”(ì˜µì…˜)
                if NORMALIZE_TO_SHOULDERS:
                    seq = np.stack([normalize_by_shoulders(f) for f in seq], axis=0)

                np.save(out_path, seq)
                converted_counts[gloss_id] += 1
                print(f"  â¬‡ï¸ ì €ì¥: {out_path} (shape={seq.shape})")

            except Exception as e:
                print(f"  âŒ ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬ ì˜¤ë¥˜({out_name}): {e}")
                continue

    cap.release()

# ==== ìš”ì•½ ====
print("\nğŸ‰ ì „ì²´ ë³€í™˜ ì™„ë£Œ (ì €ì¥ ê¸°ì¤€)")
print("ğŸ“Š ìƒˆë¡œ ì €ì¥ëœ íŒŒì¼ ê°œìˆ˜:")
for label, count in converted_counts.items():
    print(f"  - {label}: {count}ê°œ ì €ì¥ë¨")